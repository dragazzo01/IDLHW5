Midterm Report——Team 3

Introduction:

In this research project we implement a diffusion model. This model is capable of generating high quality images of a specific subject given training examples in a dataset. For instance the diffiusion model can create a high quality novel image of a cat given a dataset of cat images. Diffusion models are important as they are able to train more stably and generate more diverse, higher quality images than other generative models such as GANs.

Our goal is to minimize the Frechet Inception distance. Given two distributions, N(µr,Σr) and N(µg,Σg), the distance is computed as ||µr −µg||2 +Tr(Σr +Σg −2(ΣrΣg)1/2). 


We use techniques from the following papers: Denoising Diffusion Probabilistic Models (Ho, Jain, Abbeel), Denoising diffusion implicit models (Song, Meng, Ermon), High-resolution image synthesis with latent diffusion models (Rombach et. al.), Auto-encoding variational bayes (Kingma), and Taming transformers for highresolution image synthesis (Esser et. al). 

The Song paper describes the FID distance that we used as an evaluation metric. The Ho paper  




Methodology:

The DDPM model can be thought of as a Markov chain where at each step in the forward process Gaussian noise is added to the data. In the backward process the model is trained to remove the noise at each step. A U-net architecture with positional encodings and attention mechanisms is used in the model. The input during the training phase is an image from the dataset and the inference phase is pure Gaussian noise. The output from the training phase is the predicted noise added and for the inference phase is the newly generated image.


The dataset is a 130,000 image dataset with 100 classes. Each image is resized to be 128x128 pixels and the data is then loaded into batches to train efficiently.

As mentioned earlier we use the Frechet Inception Distance to evaluate the model where a lower distance is better.

We use mean squared error as a loss function that calculates the error between the noise was actually added during the forward process and the noise predicted by the model.

Results (generated images):

__TODO TODO____

Future directions:

Now that we have completed the DDPM model, we will implement a latent diffusion model and a classifier free guidance model. We will also consider implementing a Neurite Orientation Dispersion and Density Imaging model.
